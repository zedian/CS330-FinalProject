{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "09b64e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08291b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564adfcd434c41d59540fb5fdc502239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca813208be441e09b4614e930a06518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c79c5f62e9147aaa92acb6c84627221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6dce498d824d43b1e44a0e8ac400ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST('/tmp/mnist', download=True, train=True)\n",
    "mnist_test = torchvision.datasets.MNIST('/tmp/mnist', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caab11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist_train.data\n",
    "y_train = mnist_train.targets\n",
    "\n",
    "x_test = mnist_test.data\n",
    "y_test = mnist_test.targets\n",
    "\n",
    "t0_digit = 3\n",
    "t1_digit = 8\n",
    "\n",
    "# NOTE: x_train, x_test remains the same for both tasks\n",
    "\n",
    "y_t0_train = torch.where(y_train == t0_digit, 1, 0)\n",
    "y_t0_test = torch.where(y_test == t0_digit, 1, 0)\n",
    "y_t1_train = torch.where(y_train == t1_digit, 1, 0)\n",
    "y_t1_test = torch.where(y_test == t1_digit, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09836489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataset:\n",
    "    def __init__(self, x, t0_y, t1_y):\n",
    "        self.x = x\n",
    "        self.t0_y = t0_y\n",
    "        self.t1_y = t1_y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx] / 255., self.t0_y[idx], self.t1_y[idx]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "61b76190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL(nn.Module):\n",
    "    \"\"\"Generic multi-task learner.\"\"\"\n",
    "\n",
    "    def __init__(self, shared=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shared = shared\n",
    "    \n",
    "        self.linear1 = nn.Linear(28 * 28, 256)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(256, 32)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "#         if not self.shared:\n",
    "#             self.backbone2 = nn.Sequential(\n",
    "#                 nn.Linear(28 * 28, 256),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(256, 32),\n",
    "#                 nn.ReLU()\n",
    "#             )\n",
    "                \n",
    "        self.t0_head = nn.Linear(32, 1)\n",
    "        self.t1_head = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        t0_logits = self.t0_head(self.act2(self.linear2(self.act1(self.linear1(x)))))\n",
    "        t1_logits = self.t1_head(self.act2(self.linear2(self.act1(self.linear1(x)))))\n",
    "#         if not self.shared:\n",
    "#             t1_logits = self.t1_head(self.backbone2(x))\n",
    "#         else:\n",
    "#             t1_logits = self.t1_head(self.backbone(x))\n",
    "        \n",
    "        return t0_logits, t1_logits\n",
    "    \n",
    "    def loss(self, x, t0_y, t1_y, t0_lambda=1.0, t1_lambda=1.0):\n",
    "        t0_logits, t1_logits = self.forward(x)\n",
    "        t0_logits = t0_logits.view(-1,)\n",
    "        t1_logits = t1_logits.view(-1,)\n",
    "        \n",
    "        t0_loss = nn.functional.binary_cross_entropy_with_logits(t0_logits, t0_y)\n",
    "        t1_loss = nn.functional.binary_cross_entropy_with_logits(t1_logits, t1_y)\n",
    "        total_loss = t0_lambda * t0_loss + t1_lambda * t1_loss\n",
    "        losses = {\n",
    "            'loss/total': total_loss,\n",
    "            'loss/t0': t0_loss,\n",
    "            'loss/t1': t1_loss,\n",
    "        }\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0981f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mtl(\n",
    "    *, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    lr=1e-3, \n",
    "    epochs=5, \n",
    "):\n",
    "    model = MTL()\n",
    "    t0_model = MTL()\n",
    "    t1_model = MTL()\n",
    "    \n",
    "    linear_lr = []\n",
    "    shared_lr = []\n",
    "    for k, v in model.named_parameters():\n",
    "        if \"linear\" in k and \"weight\" in k:\n",
    "            linear_lr.append([v])\n",
    "        else:\n",
    "            shared_lr.append(v)\n",
    "#     parameters = [{\"params\": linear_lr}, {\"params\": shared_lr}]\n",
    "    parameters = [{\"params\": linear_lr[0]}, {\"params\": linear_lr[1]}, {\"params\": shared_lr}]\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    t0_optimizer = torch.optim.Adam(t0_model.param_groups, lr = lr)\n",
    "    t1_optimizer = torch.optim.Adam(t1_model.param_groups, lr = lr)\n",
    "    \n",
    "    train_metrics = {'loss/total': [], \n",
    "                     'loss/t0': [], \n",
    "                     'loss/t1': [],\n",
    "                     'acc/t0': [],\n",
    "                     'acc/t1': [],\n",
    "                    }\n",
    "    val_metrics = {'loss/total': [], \n",
    "                     'loss/t0': [], \n",
    "                     'loss/t1': [],\n",
    "                     'acc/t0': [],\n",
    "                     'acc/t1': [],\n",
    "                    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        last_10_it = len(train_loader) - 1\n",
    "        for i, batch in tqdm(enumerate(train_loader), total=len(train_loader)):    \n",
    "            im, t0_labels, t1_labels = batch\n",
    "            \n",
    "            loss = model.loss(im, t0_labels.float(), t1_labels.float())\n",
    "            total_loss = loss['loss/total']\n",
    "            t0_loss = loss['loss/t0']\n",
    "            t1_loss = loss['loss/t1']\n",
    "\n",
    "            \n",
    "            total_loss.backward(retain_graph=True)\n",
    "            rgn = 1\n",
    "#             for k, v in model.named_parameters():\n",
    "#                 grad = torch.autograd.grad(t0_loss, v, allow_unused=True, retain_graph=True)\n",
    "#                 if grad[0] is not None:\n",
    "#                     t0_rgn[k] = torch.linalg.norm(grad[0]/v)\n",
    "#             t0_loss.backward(retain_graph=True)\n",
    "#             t1_loss.backward()\n",
    "            if i == last_it:\n",
    "                t0_model.load_state_dict(model.state_dict())\n",
    "                t0_optimizer.load_state_dict(optimizer.state_dict())\n",
    "                t1_model.load_state_dict(model.state_dict())\n",
    "                t1_optimizer.load_state_dict(optimizer.state_dict())\n",
    "            if i >= last_it:\n",
    "                for g in t0_optimizer.param_groups:\n",
    "                    grad = torch.autograd.grad(t0_loss, g[\"params\"][0], allow_unused=True, retain_graph=True)\n",
    "                    if grad[0] is not None:\n",
    "                        rgn = torch.linalg.norm(grad[0]/torch.linalg.norm(g[\"params\"][0]))\n",
    "                    g[\"lr\"] = rgn*g[\"lr\"]\n",
    "                for g in t1_optimizer.param_groups:\n",
    "                    grad = torch.autograd.grad(t1_loss, g[\"params\"][0], allow_unused=True, retain_graph=True)\n",
    "                    if grad[0] is not None:\n",
    "                        rgn = torch.linalg.norm(grad[0]/torch.linalg.norm(g[\"params\"][0]))\n",
    "                    g[\"lr\"] = rgn*g[\"lr\"]\n",
    "                t0_optimizer.step()\n",
    "                t1_optimizer.step()\n",
    "                \n",
    "                t0_optimizer.zero_grad()\n",
    "                t1_optimizer.zero_grad()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # loss metrics\n",
    "            for k in train_metrics.keys():\n",
    "                if k in loss:\n",
    "                    train_metrics[k].append(loss[k].item())\n",
    "\n",
    "            # accuracy metrics\n",
    "            t0_logits, t1_logits = model.forward(im)\n",
    "            t0_pred = nn.functional.sigmoid(t0_logits) > 0.5\n",
    "            t1_pred = nn.functional.sigmoid(t1_logits) > 0.5\n",
    "            train_metrics['acc/t0'].append(accuracy(t0_pred[:, 0], t0_labels.bool()))\n",
    "            train_metrics['acc/t1'].append(accuracy(t1_pred[:, 0], t1_labels.bool()))\n",
    "\n",
    "\n",
    "        t0_val_loss = 0\n",
    "        t1_val_loss = 0\n",
    "        t0_val_acc = 0\n",
    "        t1_val_acc = 0\n",
    "        val_count = 0\n",
    "\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            im, t0_labels, t1_labels = batch\n",
    "            val_loss = model.loss(im, t0_labels.float(), t1_labels.float())\n",
    "\n",
    "            val_count += len(im)        \n",
    "            t0_val_loss += val_loss['loss/t0'].item() * len(im)\n",
    "            t1_val_loss += val_loss['loss/t1'].item() * len(im)\n",
    "\n",
    "            # accuracy metrics\n",
    "            t0_logits, t1_logits = model.forward(im)\n",
    "            t0_pred = torch.sigmoid(t0_logits) > 0.5\n",
    "            t1_pred = torch.sigmoid(t1_logits) > 0.5\n",
    "            t0_val_acc += accuracy(t0_pred[:, 0], t0_labels.bool()).item() * len(im)\n",
    "            t1_val_acc += accuracy(t1_pred[:, 0], t1_labels.bool()).item() * len(im)\n",
    "\n",
    "        val_metrics['loss/t0'].append(t0_val_loss / val_count)\n",
    "        val_metrics['loss/t1'].append(t1_val_loss / val_count)\n",
    "        val_metrics['acc/t0'].append(t0_val_acc / val_count)\n",
    "        val_metrics['acc/t1'].append(t1_val_acc / val_count)\n",
    "    \n",
    "    return train_metrics, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f5eb1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    assert y_hat.shape == y.shape\n",
    "    n_classes = y_hat.shape[-1]\n",
    "    y_hat = y_hat.view(-1, n_classes)\n",
    "    y = y.view(-1, n_classes)\n",
    "    n_correct = torch.sum(y_hat == y)\n",
    "    return n_correct / y_hat.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "12aecd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LR = 3e-4\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_ds = MultiTaskDataset(x_train, y_t0_train, y_t1_train)\n",
    "val_ds = MultiTaskDataset(x_test, y_t0_test, y_t1_test)\n",
    "train_iter = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_iter = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c2c0ec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 118/118 [00:00<00:00, 141.35it/s]\n",
      "100%|████████████████████████████████████████| 118/118 [00:00<00:00, 148.69it/s]\n",
      "100%|████████████████████████████████████████| 118/118 [00:00<00:00, 138.12it/s]\n",
      "100%|████████████████████████████████████████| 118/118 [00:00<00:00, 146.88it/s]\n",
      "100%|████████████████████████████████████████| 118/118 [00:00<00:00, 140.55it/s]\n"
     ]
    }
   ],
   "source": [
    "_, shared_metrics = train_mtl(\n",
    "    train_loader=train_iter, \n",
    "    val_loader=val_iter,\n",
    "    lr=LR, \n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b3f7d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/total': [], 'loss/t0': [0.15632205335299174, 0.15356650929450988, 0.15347934050957363, 0.15347577875057855, 0.15347576359510423], 'loss/t1': [0.23573486652374268, 0.23160629379749298, 0.2314805144548416, 0.2314755568186442, 0.23147552610238392], 'acc/t0': [0.9552333333333334, 0.9554, 0.9554166666666667, 0.9554166666666667, 0.9554166666666667], 'acc/t1': [0.9178666666348775, 0.9202666666666667, 0.9204, 0.9204, 0.9204]}\n"
     ]
    }
   ],
   "source": [
    "print(shared_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab3454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Meta-RL (ipykernel)",
   "language": "python",
   "name": "meta-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
